# E2E pipeline

This example is explained more in details in this blog post 
https://ubuntu.com/blog/mlops-pipeline-with-mlflow-seldon-core-and-kubeflow-pipelines.

## Notebook

The `e2e-kfp-mlflow-seldon-pipeline` notebook contains the simplified
implementation of the same functionality pipeline as `pipeline.py`.

Notebook shows the end-to-end process of developing and execution of the pipeline
steps locally and in the working Kubeflow installation.

## Build the components using your image registry

Go to the components/deploy folder and use `build_image.sh` to have your own image. 
You will need a DockerHub account to pull and create the new image. Read through 
components/deploy/README for more details. 
In the components/deploy/component.yaml file, update the value for "image" with the 
new image name.

## Build pipeline

Run the `pipeline.py` script. The generated pipeline will be in the `generated`
folder

## Validate Minio Access

Validate access to Minio by looking up the values for "access-key" and "secret-key" in the 
charm configuration. 
` juju config minio access-key`
` juju config minio secret-key`

If the values are not defined, apply a new user/password with the juju commands. 
` juju config minio access-key=newuser`
` juju config minio secret-key=newpassword`

Test your access to Minio by accessing the dashboard. You can change the service to be of LoadBalancer 
type or use port-forwarding to access it.

### Allow the user namespace access to Minio and MLFLow
With Kubeflow 1.4, each user namespace needs to be given access to Minio and MLFlow manually. 
Apply the files `permissions/allow-minio.yaml` and `permissions/allow-mlflow.yaml` to your user ns. 

For example, if the user is the "admin" namespace:
`kubectl apply -f permissions/allow-minio.yaml -n admin` 
`kubectl apply -f permissions/allow-mlflow.yaml -n admin` 

## Create the necessary buckets for this pipeline

This pipeline expects buckets `mlflow` and `mlpipeline` 
to exist in Minio. You can create those manually in the Minio UI. 

## Run pipeline

1. Upload the pipeline using the UI
2. Start a run, use for the `url` parameter
   use: `https://raw.githubusercontent.com/canonical/kubeflow-examples/main/e2e-wine-kfp-mlflow/winequality-red.csv`
3. The pipeline generates a Seldon Deployment in the user namespace. 
4. Use kubectl port-forward to connect to the pod generated by the Seldon Deployment. 
5. You can test the response from the pod by curling the service - look at `sample-prediction.sh` for an example call.

## Techniques to define tasks

1. Function based
2. Docker image based
3. Reuse of existing component from kfp repository